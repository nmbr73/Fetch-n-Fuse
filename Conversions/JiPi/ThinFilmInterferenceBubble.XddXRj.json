{"Shader":{"ver":"0.1","info":{"id":"XddXRj","date":"1462051646","viewed":1632,"name":"Thin-Film Interference Bubble","username":"cornusammonis","description":"Simulates thin-film interference patterns on a bubble.  If the bubble appears to be mostly white, check the BUG NOTICE in the source.","likes":14,"published":3,"flags":0,"usePreview":0,"tags":["interference","bubble","thinfilm"],"hasliked":0},"renderpass":[{"inputs":[{"id":10,"src":"\/media\/a\/92d7758c402f0927011ca8d0a7e40251439fba3a1dac26f5b8b62026323501aa.jpg","ctype":"texture","channel":1,"sampler":{"filter":"mipmap","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":22,"src":"\/media\/a\/585f9546c092f53ded45332b343144396c0b2d70d9965f585ebc172080d8aa58.jpg","ctype":"cubemap","channel":0,"sampler":{"filter":"mipmap","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":37,"channel":0}],"code":"\/*\n\tThin-Film Interference Bubble\n\n\tThis shader simulates thin-film interference patterns with a reasonable degree of accuracy.\n\tChromatic dispersion is also simulated, and both effects use more than 3 wavelengths of light\n\tto increase accuracy. An arbitrary number of wavelengths can be simulated, which are then\n    downsampled to RGB, in a similar fashion to the human eye.\n\n*\/\n\n\/* \n\tBUG NOTICE!\n\tOn some platforms (lower-end Nvidia graphics seem to be the common factor)\n\tthe reflectance is much brighter than it's supposed to be. If the bubble\n\tlooks mostly white on your platform, uncomment this next line:\n*\/\n\/\/#define ITS_TOO_BRIGHT\n\n\/\/ To see just the reflection (no refraction\/transmission) uncomment this next line:\n\/\/#define REFLECTANCE_ONLY\n\n\/\/ performance and raymarching options\n#define WAVELENGTHS 5\t\t\t\t \/\/ number of rays of different wavelengths to simulate, should be >= 3\n#define INTERSECTION_PRECISION 0.01  \/\/ raymarcher intersection precision\n#define MIN_INCREMENT 0.02\t\t\t \/\/ distance stepped when entering the surface of the distance field\n#define ITERATIONS 50\t\t\t\t \/\/ max number of iterations\n#define MAX_BOUNCES 2\t\t\t\t \/\/ max number of reflection\/refraction bounces\n#define AA_SAMPLES 1\t\t\t\t \/\/ anti aliasing samples\n#define BOUND 6.0\t\t\t\t\t \/\/ cube bounds check\n#define DIST_SCALE 0.9   \t\t\t \/\/ scaling factor for raymarching position update\n\n\/\/ optical properties\n#define DISPERSION 0.05\t\t\t\t \/\/ dispersion amount\n#define IOR 0.9     \t\t\t\t \/\/ base IOR value specified as a ratio\n#define THICKNESS_SCALE 64.0\t\t \/\/ film thickness scaling factor\n#define THICKNESS_CUBEMAP_SCALE 0.07 \/\/ film thickness cubemap scaling factor\n#define REFLECTANCE_SCALE 5.0        \/\/ reflectance scaling factor\n\n#define TWO_PI 6.28318530718\n#define PI 3.14159265359\n\n\/\/ visualize the average number of bounces for each of the rays\n\/\/#define VISUALIZE_BOUNCES\n\n\/\/ iq's cubemap function\nvec3 fancyCube( sampler2D sam, in vec3 d, in float s, in float b )\n{\n    vec3 colx = textureLod( sam, 0.5 + s*d.yz\/d.x, b ).xyz;\n    vec3 coly = textureLod( sam, 0.5 + s*d.zx\/d.y, b ).xyz;\n    vec3 colz = textureLod( sam, 0.5 + s*d.xy\/d.z, b ).xyz;\n    \n    vec3 n = d*d;\n    \n    return (colx*n.x + coly*n.y + colz*n.z)\/(n.x+n.y+n.z);\n}\n\n\/\/ iq's 3D noise function\nfloat hash( float n ){\n    return fract(sin(n)*43758.5453);\n}\n\nfloat noise( in vec3 x ) {\n    vec3 p = floor(x);\n    vec3 f = fract(x);\n\n    f = f*f*(3.0-2.0*f);\n    float n = p.x + p.y*57.0 + 113.0*p.z;\n    return mix(mix(mix( hash(n+  0.0), hash(n+  1.0),f.x),\n                   mix( hash(n+ 57.0), hash(n+ 58.0),f.x),f.y),\n               mix(mix( hash(n+113.0), hash(n+114.0),f.x),\n                   mix( hash(n+170.0), hash(n+171.0),f.x),f.y),f.z);\n}\n\nvec3 noise3(vec3 x) {\n\treturn vec3( noise(x+vec3(123.456,.567,.37)),\n\t\t\t\tnoise(x+vec3(.11,47.43,19.17)),\n\t\t\t\tnoise(x) );\n}\n\n\/\/ a sphere with a little bit of warp\nfloat sdf( vec3 p ) {\n\tvec3 n = pow(vec3(sin(iDate.w * 0.5), sin(iDate.w * 0.3), cos(iDate.w * 0.2)), vec3(2.0));\n\tvec3 q = 0.1 * noise3(p + n);\n  \n\treturn length(q + p)-3.5;\n}\n\n\/\/ Fresnel factor from TambakoJaguar Diamond Test shader here: https:\/\/www.shadertoy.com\/view\/XdtGDj\n\/\/ see also: https:\/\/en.wikipedia.org\/wiki\/Schlick's_approximation\nfloat fresnel( vec3 ray, vec3 norm, float n2 )\n{\n   float n1 = 1.0;\n   float angle = clamp(acos(-dot(ray, norm)), -3.14\/2.15, 3.14\/2.15);\n   float r0 = pow((n1-n2)\/(n1+n2), 2.);\n   float r = r0 + (1. - r0)*pow(1. - cos(angle), 5.);\n   return clamp(0., 1.0, r);\n}\n\nvec3 calcNormal( in vec3 pos ) {\n    const float eps = INTERSECTION_PRECISION;\n\n    const vec3 v1 = vec3( 1.0,-1.0,-1.0);\n    const vec3 v2 = vec3(-1.0,-1.0, 1.0);\n    const vec3 v3 = vec3(-1.0, 1.0,-1.0);\n    const vec3 v4 = vec3( 1.0, 1.0, 1.0);\n\n\treturn normalize( v1*sdf( pos + v1*eps ) + \n\t\t\t\t\t  v2*sdf( pos + v2*eps ) + \n\t\t\t\t\t  v3*sdf( pos + v3*eps ) + \n\t\t\t\t\t  v4*sdf( pos + v4*eps ) );\n}\n\nstruct Bounce\n{\n    vec3 position;\n    vec3 ray_direction;\n    float attenuation;\n    float reflectance;\n    float ior;\n    float bounces;\n    float wavelength;\n};\n    \nfloat sigmoid(float t, float t0, float k) {\n    return 1.0 \/ (1.0 + exp(-k*(t - t0)));  \n}\n\n#define GAMMA_CURVE 50.0\n#define GAMMA_SCALE 4.5\n\nvec3 filmic_gamma(vec3 x) {\n\treturn log(GAMMA_CURVE * x + 1.0) \/ GAMMA_SCALE;    \n}\n\nfloat filmic_gamma_inverse(float y) {\n\treturn (1.0\/GAMMA_CURVE) * (-1.0 + exp(GAMMA_SCALE * y)); \n}\n\n\/\/ sample weights for the cubemap given a wavelength i\n\/\/ room for improvement in this function\nvec3 texCubeSampleWeights(float i) {\n\tvec3 w = vec3((1.0 - i) * (1.0 - i), 2.0 * i * (1.0 - i), i * i);\n    return w \/ dot(w, vec3(1.0));\n}\n\nfloat sampleCubeMap(float i, vec3 rd) {\n\tvec3 col = textureLod(iChannel0, rd * vec3(1.0,-1.0,1.0), 0.0).xyz; \n    return dot(texCubeSampleWeights(i), col);\n}\n\nvoid doCamera( out vec3 camPos, out vec3 camTar, in float time, in vec4 m ) {\n    camTar = vec3(0.0,0.0,0.0); \n    if (max(m.z, m.w) <= 0.0) {\n    \tfloat an = 1.5 + sin(time * 0.05) * 4.0;\n\t\tcamPos = vec3(6.5*sin(an), 0.0 ,6.5*cos(an));   \n    } else {\n    \tfloat an = 10.0 * m.x - 5.0;\n\t\tcamPos = vec3(6.5*sin(an),10.0 * m.y - 5.0,6.5*cos(an)); \n    }\n}\n\nmat3 calcLookAtMatrix( in vec3 ro, in vec3 ta, in float roll )\n{\n    vec3 ww = normalize( ta - ro );\n    vec3 uu = normalize( cross(ww,vec3(sin(roll),cos(roll),0.0) ) );\n    vec3 vv = normalize( cross(uu,ww));\n    return mat3( uu, vv, ww );\n}\n\n\/\/ MATLAB Jet color scheme\nvec3 jet(float x) {\n\n   x = clamp(x, 0.0, 1.0);\n\n   if (x < 0.25) {\n       return(vec3(0.0, 4.0 * x, 1.0));\n   } else if (x < 0.5) {\n       return(vec3(0.0, 1.0, 1.0 + 4.0 * (0.25 - x)));\n   } else if (x < 0.75) {\n       return(vec3(4.0 * (x - 0.5), 1.0, 0.0));\n   } else {\n       return(vec3(1.0, 1.0 + 4.0 * (0.75 - x), 0.0));\n   }\n   \n}\n\n\/\/ 4PL curve fit to experimentally-determined values\nfloat greenWeight() {\n    float a = 4569547.0;\n    float b = 2.899324;\n    float c = 0.008024607;\n    float d = 0.07336188;\n\n    return d + (a - d) \/ (1.0 + pow(log(float(WAVELENGTHS))\/c, b)) + 2.0;    \n}\n\n\/\/ sample weights for downsampling to RGB. Ideally this would be close to the \n\/\/ RGB response curves for the human eye, instead I use a simple ad hoc solution here.\n\/\/ Could definitely be improved upon.\nvec3 sampleWeights(float i) {\n\treturn vec3((1.0 - i) * (1.0 - i), greenWeight() * i * (1.0 - i), i * i);\n}\n\n\/\/ downsample to RGB\nvec3 resampleColor(Bounce[WAVELENGTHS] bounces) {\n    vec3 col = vec3(0.0);\n    \n    for (int i = 0; i < WAVELENGTHS; i++) {        \n        float reflectance = bounces[i].reflectance;\n        float index = float(i) \/ float(WAVELENGTHS - 1);\n        float texCubeIntensity = filmic_gamma_inverse(\n            clamp(bounces[i].attenuation * sampleCubeMap(index, bounces[i].ray_direction), 0.0, 0.99)\n        );\n    \tfloat intensity = texCubeIntensity + reflectance;\n        col += sampleWeights(index) * intensity;\n    }\n\n    return 1.3 * filmic_gamma(2.0 * col \/ float(WAVELENGTHS));\n}\n\n\/\/ compute average number of bounces for the VISUALIZE_BOUNCES render mode\nfloat avgBounces(Bounce[WAVELENGTHS] bounces) {\n    float avg = 0.0;\n    \n    for (int i = 0; i < WAVELENGTHS; i++) {        \n         avg += bounces[i].bounces;;\n    }\n\n    return avg \/ float(WAVELENGTHS);\n}\n\n\/\/ compute the wavelength\/IOR curve values.\nfloat iorCurve(float x) {\n\treturn x;\n}\n\nBounce initialize(vec3 ro, vec3 rd, float i) {\n    i = i \/ float(WAVELENGTHS - 1);\n    float ior = IOR + iorCurve(1.0 - i) * DISPERSION;\n    return Bounce(ro, rd, 1.0, 0.0, ior, 1.0, i); \n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    vec2 p = (-iResolution.xy + 2.0*fragCoord.xy)\/iResolution.y;\n    vec4 m = vec4(iMouse.xy\/iResolution.xy, iMouse.zw);\n\n    \/\/ camera movement\n    vec3 ro, ta;\n    doCamera( ro, ta, iTime, m );\n    mat3 camMat = calcLookAtMatrix( ro, ta, 0.0 );\n    \n    float dh = (0.5 \/ iResolution.y);\n    const float rads = TWO_PI \/ float(AA_SAMPLES);\n    \n    Bounce bounces[WAVELENGTHS];\n    \n    vec3 col = vec3(0.0);\n    \n    for (int samp = 0; samp < AA_SAMPLES; samp++) {\n        vec2 dxy = dh * vec2(cos(float(samp) * rads), sin(float(samp) * rads));\n        vec3 rd = normalize(camMat * vec3(p.xy + dxy, 1.5)); \/\/ 1.5 is the lens length\n\n        for (int i = 0; i < WAVELENGTHS; i++) {\n            bounces[i] = initialize(ro, rd, float(i));    \n        }\n\n        for (int i = 0; i < WAVELENGTHS; i++) {\n            for (int j = 0; j < ITERATIONS; j++) {\n                float td = DIST_SCALE * sdf(bounces[i].position);\n                float t = abs(td);\n                float sig = sign(td);    \n                \n                vec3 pos = bounces[i].position + t * bounces[i].ray_direction;\n                if ( (sig > 0.0 && bounces[i].bounces > 1.0) \n                    || int(bounces[i].bounces) >= MAX_BOUNCES \n                    || clamp(pos, -BOUND, BOUND) != pos) {\n                \tbreak;    \n                } else if ( t < INTERSECTION_PRECISION ) {\n                    vec3 normal = calcNormal(pos);\n                    \n                    #ifdef REFLECTANCE_ONLY\n                    \tbounces[i].attenuation = 0.0;\n                    #endif\n                    \n                    float filmThickness = fancyCube( iChannel1, normal, THICKNESS_CUBEMAP_SCALE, 0.0 ).x + 0.1;\n                    \n                    float attenuation = 0.5 + 0.5 * cos(((THICKNESS_SCALE * filmThickness)\/(bounces[i].wavelength + 1.0)) * dot(normal, bounces[i].ray_direction));\n                    float ior = sig < 0.0 ? 1.0 \/ bounces[i].ior : bounces[i].ior;\n\n                    \/\/ cubemap reflection\n                    float f = fresnel(bounces[i].ray_direction, normal, 0.5 \/ ior);\n                    float texCubeSample = attenuation * sampleCubeMap(bounces[i].wavelength, reflect(bounces[i].ray_direction, normal));\n                    \n                    #ifdef ITS_TOO_BRIGHT\n                    \tbounces[i].reflectance += REFLECTANCE_SCALE * filmic_gamma_inverse(mix(0.0, 0.8 * texCubeSample - 0.1, f));\n                    #else\n                    \tbounces[i].reflectance += REFLECTANCE_SCALE * filmic_gamma_inverse(mix(0.0, 4.0 * texCubeSample - 0.5, f));\n                    #endif\n\n                    bounces[i].ray_direction = normalize(refract(bounces[i].ray_direction, normal, ior));\n                    bounces[i].position = pos + MIN_INCREMENT * bounces[i].ray_direction;\n                    bounces[i].bounces += 1.0;\n                } else {\n                    bounces[i].position = pos;\n                }\n            }\n        }\n\n        #ifdef VISUALIZE_BOUNCES\n        \tcol += jet(avgBounces(bounces) \/ float(MAX_BOUNCES));\n        #else\n        \tcol += resampleColor(bounces);\n        #endif\n    }\n    \n    col \/= float(AA_SAMPLES);\n\t   \n    fragColor = vec4( col, 1.0 );\n}","name":"Image","description":"","type":"image"}]}}