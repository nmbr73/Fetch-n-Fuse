{"Shader":{"ver":"0.1","info":{"id":"ftjyzV","date":"1649943493","viewed":22,"name":"FIRE! in the brain","username":"xenn","description":"Displacement mapping with chromatic dispersion. The displacement vectors are supplied by an underlying dynamical system. Click to paint.","likes":1,"published":3,"flags":48,"usePreview":0,"tags":["displacement","chromatic","aberration","mapping","dispersion"],"hasliked":0},"renderpass":[{"inputs":[{"id":257,"src":"\/media\/previz\/buffer00.png","ctype":"buffer","channel":3,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":260,"src":"\/media\/previz\/buffer03.png","ctype":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":260,"src":"\/media\/previz\/buffer03.png","ctype":"buffer","channel":1,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":260,"src":"\/media\/previz\/buffer03.png","ctype":"buffer","channel":2,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":37,"channel":0}],"code":"\/\/ Mashup Fork of \"Displacement with Dispersion\" by cornusammonis. https:\/\/shadertoy.com\/view\/4ldGDB\n\/\/ 2021-08-28 10:34:29\n\/\/ & this https:\/\/www.shadertoy.com\/view\/MsGSRd by flockeroo\n\n#define Margins .0\n\n\n\nvec3 ACESFilm(vec3 x)\n{\n    float a = 2.51;\n    float b = 0.03;\n    float c = 2.43;\n    float d = 0.59;\n    float e = 0.14;\n    return (x*(a*x+b))\/(x*(c*x+d)+e);\n}\n\nvec3 bloom(float scale, float threshold, vec2 fragCoord){\n    float logScale = log2(scale)+1.0;\n    \n    vec3 bloom = vec3(0);\n    for(int y = -1; y <= 1; y++)\n        for(int x = -1; x <= 1; x++)\n            bloom += textureLod(iChannel0, (fragCoord+vec2(x, y) * scale)\/iResolution.xy, logScale).rgb;\n    \n    return max(bloom\/9.0 - vec3(threshold), vec3(0));\n}\n\n\/\/Chromatic aberration, film grain and tone mapping\n\nfloat NoiseSeed;\n\nfloat randomFloat(){\n  NoiseSeed = sin(NoiseSeed) * 84522.13219145687;\n  return fract(NoiseSeed);\n}\n\nvec3 ACESFilm2(vec3 x)\n{\n    float a = 2.51;\n    float b = 0.03;\n    float c = 2.43;\n    float d = 0.59;\n    float e = 0.14;\n    return (x*(a*x+b))\/(x*(c*x+d)+e);\n}\n\n\nfloat getVal(vec2 uv)\n{\n    return length(texture(iChannel0,uv).xyz);\n}\n    \nvec2 getGrad(vec2 uv,float delta)\n{\n    vec2 d=vec2(delta,0);\n    return vec2(\n        getVal(uv+d.xy)-getVal(uv-d.xy),\n        getVal(uv+d.yx)-getVal(uv-d.yx)\n    )\/delta;\n}\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord ) {\n    \n    if(fragCoord.y \/ iResolution.y < Margins || fragCoord.y \/ iResolution.y > 1.0-Margins){\n        fragColor = vec4(ACESFilm(vec3(0)), 1.0);\n        return;\n    }\n    \n    NoiseSeed = float(iFrame)* .003186154 + fragCoord.y * 17.2986546543 + fragCoord.x;\n    \n    vec2 uv = fragCoord.xy\/iResolution.xy;\n    \n    vec2 d = (uv-vec2(.5)) * .0075;\n    vec3 color = vec3(texture(iChannel0, uv - 0.0 * d).r,\n                      texture(iChannel0, uv - 1.0 * d).g,\n                      texture(iChannel0, uv - 2.0 * d).b);\n    \n    \n    float noise = .9 + randomFloat()*.15;\n\/\/  \tfragColor = vec4(ACESFilm(color*noise), 1.0);\n\/\/}\n\n\/\/void mainImage( out vec4 fragColor, in vec2 fragCoord ) {\n    vec4 frogColor;\n    vec4 frigColor;\n    vec3 col = texelFetch(iChannel1, ivec2(fragCoord), 0).rgb;\n    \n    vec3 bloomSum = bloom(.1 * iResolution.y, .9, fragCoord) * .2\n        \t\t  + bloom(.2 * iResolution.y, .5, fragCoord) * .2;\n\/\/    frogColor = vec4(ACESFilm(color*noise), 1.0);\n\/\/    frigColor = mix(vec4(ACESFilm(col + bloomSum), 1.0),vec4(ACESFilm2(color*noise), 1.0),(1.0 * abs(sin(iTime * .50))));\n        frogColor = max(vec4(ACESFilm(col + bloomSum), 1.0),vec4(ACESFilm2(color*noise), 1.0));\n        frigColor = min(vec4(ACESFilm(col + bloomSum), 1.0),vec4(ACESFilm2(color*noise), 1.0));\n\nfrogColor = mix(frigColor,frogColor,1.0-(0.999*(cos(iTime\/3.14159265359))));\n\/\/ fragColor = max(vec4(ACESFilm(col + bloomSum), 1.0),vec4(ACESFilm2(color*noise), 1.0));\n\/\/}\n\n\/\/void mainImage( out vec4 fragColor, in vec2 fragCoord )\n\/\/{\n\/\/\tvec2 uv = fragCoord.xy \/ iResolution.xy;\n    vec3 n = vec3(getGrad(uv,1.0\/iResolution.y),440.0);\n    \/\/n *= n;\n    n=normalize(n);\n    fragColor=vec4(n,1);\n    vec3 light = normalize(vec3(1,1,2));\n    float diff=clamp(dot(n,light),0.5,1.0);\n    float spec=clamp(dot(reflect(light,n),vec3(0,0,-1)),0.0,1.0);\n    spec=pow(spec,50.0)*.85;\n    \/\/spec=0.0;\n\tvec4 frugColor = texture(iChannel2,uv)*vec4(diff)+vec4(spec);\n    frugColor *= frogColor;\n    frugColor *= frogColor;\n    fragColor = frugColor;\n}","name":"Image","description":"","type":"image"},{"inputs":[{"id":16,"src":"\/media\/a\/3083c722c0c738cad0f468383167a0d246f91af2bfa373e9c5c094fb8c8413e0.png","ctype":"texture","channel":1,"sampler":{"filter":"mipmap","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":33,"src":"\/presets\/tex00.jpg","ctype":"keyboard","channel":3,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":259,"src":"\/media\/previz\/buffer02.png","ctype":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":260,"src":"\/media\/previz\/buffer03.png","ctype":"buffer","channel":2,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":257,"channel":0}],"code":"\/*\n    A fracturing dynamical system\n\tsee: https:\/\/www.shadertoy.com\/view\/MsyXRW\n*\/\n\n#define _G0 0.25\n#define _G1 0.125\n#define _G2 0.0625\n#define W0 -3.0\n#define W1 0.5\n#define TIMESTEP 0.1\n#define ADVECT_DIST 2.0\n#define DV 0.70710678\n\n\/\/ nonlinearity\nfloat nl(float x) {\n    return 1.0 \/ (1.0 + exp(W0 * (W1 * x - 0.5))); \n}\n\nvec4 gaussian(vec4 x, vec4 x_nw, vec4 x_n, vec4 x_ne, vec4 x_w, vec4 x_e, vec4 x_sw, vec4 x_s, vec4 x_se) {\n    return _G0*x + _G1*(x_n + x_e + x_w + x_s) + _G2*(x_nw + x_sw + x_ne + x_se);\n}\n\nbool reset() {\n    return texture(iChannel3, vec2(32.5\/256.0, 0.5) ).x > 0.5;\n}\n\nvec2 normz(vec2 x) {\n\treturn x == vec2(0.0, 0.0) ? vec2(0.0, 0.0) : normalize(x);\n}\n\nvec4 advect(vec2 ab, vec2 vUv, vec2 step) {\n    \n    vec2 aUv = vUv - ab * ADVECT_DIST * step;\n    \n    vec2 n  = vec2(0.0, step.y);\n    vec2 ne = vec2(step.x, step.y);\n    vec2 e  = vec2(step.x, 0.0);\n    vec2 se = vec2(step.x, -step.y);\n    vec2 s  = vec2(0.0, -step.y);\n    vec2 sw = vec2(-step.x, -step.y);\n    vec2 w  = vec2(-step.x, 0.0);\n    vec2 nw = vec2(-step.x, step.y);\n\n    vec4 u =    texture(iChannel0, fract(aUv));\n    vec4 u_n =  texture(iChannel0, fract(aUv+n));\n    vec4 u_e =  texture(iChannel0, fract(aUv+e));\n    vec4 u_s =  texture(iChannel0, fract(aUv+s));\n    vec4 u_w =  texture(iChannel0, fract(aUv+w));\n    vec4 u_nw = texture(iChannel0, fract(aUv+nw));\n    vec4 u_sw = texture(iChannel0, fract(aUv+sw));\n    vec4 u_ne = texture(iChannel0, fract(aUv+ne));\n    vec4 u_se = texture(iChannel0, fract(aUv+se));\n    \n    return gaussian(u, u_nw, u_n, u_ne, u_w, u_e, u_sw, u_s, u_se);\n}\n\n#define SQRT_3_OVER_2 0.86602540378\n#define SQRT_3_OVER_2_INV 0.13397459621\n\nvec2 diagH(vec2 x, vec2 x_v, vec2 x_h, vec2 x_d) {\n    return 0.5 * ((x + x_v) * SQRT_3_OVER_2_INV + (x_h + x_d) * SQRT_3_OVER_2);\n}\n\nvec2 diagV(vec2 x, vec2 x_v, vec2 x_h, vec2 x_d) {\n    return 0.5 * ((x + x_h) * SQRT_3_OVER_2_INV + (x_v + x_d) * SQRT_3_OVER_2);\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    vec2 vUv = fragCoord.xy \/ iResolution.xy;\n    vec2 texel = 1. \/ iResolution.xy;\n    \n    vec2 n  = vec2(0.0, 1.0);\n    vec2 ne = vec2(1.0, 1.0);\n    vec2 e  = vec2(1.0, 0.0);\n    vec2 se = vec2(1.0, -1.0);\n    vec2 s  = vec2(0.0, -1.0);\n    vec2 sw = vec2(-1.0, -1.0);\n    vec2 w  = vec2(-1.0, 0.0);\n    vec2 nw = vec2(-1.0, 1.0);\n\n\/*    vec4 u =    texture(iChannel0, fract(vUv));\n    vec4 u_n =  texture(iChannel0, fract(vUv+texel*n));\n    vec4 u_e =  texture(iChannel0, fract(vUv+texel*e));\n    vec4 u_s =  texture(iChannel0, fract(vUv+texel*s));\n    vec4 u_w =  texture(iChannel0, fract(vUv+texel*w));\n    vec4 u_nw = texture(iChannel0, fract(vUv+texel*nw));\n    vec4 u_sw = texture(iChannel0, fract(vUv+texel*sw));\n    vec4 u_ne = texture(iChannel0, fract(vUv+texel*ne));\n    vec4 u_se = texture(iChannel0, fract(vUv+texel*se));\n*\/    \n    vec4 u =    texture(iChannel2, fract(vUv));\n    vec4 u_n =  texture(iChannel2, fract(vUv+texel*n));\n    vec4 u_e =  texture(iChannel2, fract(vUv+texel*e));\n    vec4 u_s =  texture(iChannel2, fract(vUv+texel*s));\n    vec4 u_w =  texture(iChannel2, fract(vUv+texel*w));\n    vec4 u_nw = texture(iChannel2, fract(vUv+texel*nw));\n    vec4 u_sw = texture(iChannel2, fract(vUv+texel*sw));\n    vec4 u_ne = texture(iChannel2, fract(vUv+texel*ne));\n    vec4 u_se = texture(iChannel2, fract(vUv+texel*se));\n    \n    \n    const float vx = 0.5;\n    const float vy = SQRT_3_OVER_2;\n    const float hx = SQRT_3_OVER_2;\n    const float hy = 0.5;\n\n    float di_n  = nl(distance(u_n.xy + n, u.xy));\n    float di_w  = nl(distance(u_w.xy + w, u.xy));\n    float di_e  = nl(distance(u_e.xy + e, u.xy));\n    float di_s  = nl(distance(u_s.xy + s, u.xy));\n    \n    float di_nne = nl(distance((diagV(u.xy, u_n.xy, u_e.xy, u_ne.xy) + vec2(+ vx, + vy)), u.xy));\n    float di_ene = nl(distance((diagH(u.xy, u_n.xy, u_e.xy, u_ne.xy) + vec2(+ hx, + hy)), u.xy));\n    float di_ese = nl(distance((diagH(u.xy, u_s.xy, u_e.xy, u_se.xy) + vec2(+ hx, - hy)), u.xy));\n    float di_sse = nl(distance((diagV(u.xy, u_s.xy, u_e.xy, u_se.xy) + vec2(+ vx, - vy)), u.xy));    \n    float di_ssw = nl(distance((diagV(u.xy, u_s.xy, u_w.xy, u_sw.xy) + vec2(- vx, - vy)), u.xy));\n    float di_wsw = nl(distance((diagH(u.xy, u_s.xy, u_w.xy, u_sw.xy) + vec2(- hx, - hy)), u.xy));\n    float di_wnw = nl(distance((diagH(u.xy, u_n.xy, u_w.xy, u_nw.xy) + vec2(- hx, + hy)), u.xy));\n    float di_nnw = nl(distance((diagV(u.xy, u_n.xy, u_w.xy, u_nw.xy) + vec2(- vx, + vy)), u.xy));\n\n    vec2 xy_n  = u_n.xy + n - u.xy;\n    vec2 xy_w  = u_w.xy + w - u.xy;\n    vec2 xy_e  = u_e.xy + e - u.xy;\n    vec2 xy_s  = u_s.xy + s - u.xy;\n    \n    vec2 xy_nne = (diagV(u.xy, u_n.xy, u_e.xy, u_ne.xy) + vec2(+ vx, + vy)) - u.xy;\n    vec2 xy_ene = (diagH(u.xy, u_n.xy, u_e.xy, u_ne.xy) + vec2(+ hx, + hy)) - u.xy;\n    vec2 xy_ese = (diagH(u.xy, u_s.xy, u_e.xy, u_se.xy) + vec2(+ hx, - hy)) - u.xy;\n    vec2 xy_sse = (diagV(u.xy, u_s.xy, u_e.xy, u_se.xy) + vec2(+ vx, - vy)) - u.xy;\n    vec2 xy_ssw = (diagV(u.xy, u_s.xy, u_w.xy, u_sw.xy) + vec2(- vx, - vy)) - u.xy;\n    vec2 xy_wsw = (diagH(u.xy, u_s.xy, u_w.xy, u_sw.xy) + vec2(- hx, - hy)) - u.xy;\n    vec2 xy_wnw = (diagH(u.xy, u_n.xy, u_w.xy, u_nw.xy) + vec2(- hx, + hy)) - u.xy;\n    vec2 xy_nnw = (diagV(u.xy, u_n.xy, u_w.xy, u_nw.xy) + vec2(- vx, + vy)) - u.xy;\n\n    vec2 ma = di_nne * xy_nne + di_ene * xy_ene + di_ese * xy_ese + di_sse * xy_sse + di_ssw * xy_ssw + di_wsw * xy_wsw + di_wnw * xy_wnw + di_nnw * xy_nnw + di_n * xy_n + di_w * xy_w + di_e * xy_e + di_s * xy_s;\n\n    vec4 u_blur = gaussian(u, u_nw, u_n, u_ne, u_w, u_e, u_sw, u_s, u_se);\n    \n    vec4 au = advect(u.xy, vUv, texel);\n    vec4 av = advect(u.zw, vUv, texel);\n    \n    vec2 dv = av.zw + TIMESTEP * ma;\n    vec2 du = au.xy + TIMESTEP * dv;\n\n    if (iMouse.z > 0.0) {\n    \tvec2 d = fragCoord.xy - iMouse.xy;\n        float m = exp(-length(d) \/ 50.0);\n        du += 0.2 * m * normz(d);\n    }\n    \n    vec2 init = texture(iChannel1, vUv, 4.0).xy;\n    \/\/ initialize with noise\n    if((length(u) < 0.001 && length(init) > 0.001) || reset()) {\n        fragColor = 8.0 * (vec4(-0.5) + vec4(init.xy, init.xy));\n    } else {\n        du = length(du) > 1.0 ? normz(du) : du;\n        fragColor = vec4(du, dv);\n    }\n    \n\n}","name":"Buffer A","description":"","type":"buffer"},{"inputs":[{"id":257,"src":"\/media\/previz\/buffer00.png","ctype":"buffer","channel":2,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":257,"src":"\/media\/previz\/buffer00.png","ctype":"buffer","channel":3,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":259,"src":"\/media\/previz\/buffer02.png","ctype":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":258,"channel":0}],"code":"\/*\n    A fluid-like dynamical system\n\tsee: https:\/\/www.shadertoy.com\/view\/XddSRX\n*\/\n\nvec2 normz(vec2 x) {\n\treturn x == vec2(0.0, 0.0) ? vec2(0.0, 0.0) : normalize(x);\n}\n\n\/\/ reverse advection\nvec4 advect(vec2 ab, vec2 vUv, vec2 step, float sc) {\n    \n    vec2 aUv = vUv - ab * sc * step;\n    \n    const float _G0 = 0.25; \/\/ center weight\n    const float _G1 = 0.125; \/\/ edge-neighbors\n    const float _G2 = 0.0625; \/\/ vertex-neighbors\n    \n    \/\/ 3x3 neighborhood coordinates\n    float step_x = step.x;\n    float step_y = step.y;\n    vec2 n  = vec2(0.0, step_y);\n    vec2 ne = vec2(step_x, step_y);\n    vec2 e  = vec2(step_x, 0.0);\n    vec2 se = vec2(step_x, -step_y);\n    vec2 s  = vec2(0.0, -step_y);\n    vec2 sw = vec2(-step_x, -step_y);\n    vec2 w  = vec2(-step_x, 0.0);\n    vec2 nw = vec2(-step_x, step_y);\n\n    vec4 uv =    texture(iChannel0, fract(aUv));\n    vec4 uv_n =  texture(iChannel0, fract(aUv+n));\n    vec4 uv_e =  texture(iChannel0, fract(aUv+e));\n    vec4 uv_s =  texture(iChannel0, fract(aUv+s));\n    vec4 uv_w =  texture(iChannel0, fract(aUv+w));\n    vec4 uv_nw = texture(iChannel0, fract(aUv+nw));\n    vec4 uv_sw = texture(iChannel0, fract(aUv+sw));\n    vec4 uv_ne = texture(iChannel0, fract(aUv+ne));\n    vec4 uv_se = texture(iChannel0, fract(aUv+se));\n    \n    return _G0*uv + _G1*(uv_n + uv_e + uv_w + uv_s) + _G2*(uv_nw + uv_sw + uv_ne + uv_se);\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    const float _K0 = -20.0\/6.0; \/\/ center weight\n    const float _K1 = 4.0\/6.0;   \/\/ edge-neighbors\n    const float _K2 = 1.0\/6.0;   \/\/ vertex-neighbors\n    const float cs = -3.0;  \/\/ curl scale\n    const float ls = 3.0;  \/\/ laplacian scale\n    const float ps = 0.0;  \/\/ laplacian of divergence scale\n    const float ds = -12.0; \/\/ divergence scale\n    const float dp = -6.0; \/\/ divergence update scale\n    const float pl = 0.3;   \/\/ divergence smoothing\n    const float ad = 6.0;   \/\/ advection distance scale\n    const float pwr = 1.0;  \/\/ power when deriving rotation angle from curl\n    const float amp = 1.0;  \/\/ self-amplification\n    const float upd = 0.99;  \/\/ update smoothing\n    const float sq2 = 0.6;  \/\/ diagonal weight\n    \n    vec2 vUv = fragCoord.xy \/ iResolution.xy;\n    vec2 texel = 1. \/ iResolution.xy;\n    \n    \/\/ 3x3 neighborhood coordinates\n    float step_x = texel.x;\n    float step_y = texel.y;\n    vec2 n  = vec2(0.0, step_y);\n    vec2 ne = vec2(step_x, step_y);\n    vec2 e  = vec2(step_x, 0.0);\n    vec2 se = vec2(step_x, -step_y);\n    vec2 s  = vec2(0.0, -step_y);\n    vec2 sw = vec2(-step_x, -step_y);\n    vec2 w  = vec2(-step_x, 0.0);\n    vec2 nw = vec2(-step_x, step_y);\n\n \/*   vec4 uv =    texture(iChannel0, fract(vUv));\n    vec4 uv_n =  texture(iChannel0, fract(vUv+n));\n    vec4 uv_e =  texture(iChannel0, fract(vUv+e));\n    vec4 uv_s =  texture(iChannel0, fract(vUv+s));\n    vec4 uv_w =  texture(iChannel0, fract(vUv+w));\n    vec4 uv_nw = texture(iChannel0, fract(vUv+nw));\n    vec4 uv_sw = texture(iChannel0, fract(vUv+sw));\n    vec4 uv_ne = texture(iChannel0, fract(vUv+ne));\n    vec4 uv_se = texture(iChannel0, fract(vUv+se));\n  *\/  \n     vec4 uv =    texture(iChannel2, fract(vUv));\n    vec4 uv_n =  texture(iChannel2, fract(vUv+n));\n    vec4 uv_e =  texture(iChannel2, fract(vUv+e));\n    vec4 uv_s =  texture(iChannel2, fract(vUv+s));\n    vec4 uv_w =  texture(iChannel2, fract(vUv+w));\n    vec4 uv_nw = texture(iChannel2, fract(vUv+nw));\n    vec4 uv_sw = texture(iChannel2, fract(vUv+sw));\n    vec4 uv_ne = texture(iChannel2, fract(vUv+ne));\n    vec4 uv_se = texture(iChannel2, fract(vUv+se));\n    \n    \/\/ uv.x and uv.y are the x and y components, uv.z and uv.w accumulate divergence \n\n    \/\/ laplacian of all components\n    vec4 lapl  = _K0*uv + _K1*(uv_n + uv_e + uv_w + uv_s) + _K2*(uv_nw + uv_sw + uv_ne + uv_se);\n    \n    \/\/ calculate curl\n    \/\/ vectors point clockwise about the center point\n    float curl = uv_n.x - uv_s.x - uv_e.y + uv_w.y + sq2 * (uv_nw.x + uv_nw.y + uv_ne.x - uv_ne.y + uv_sw.y - uv_sw.x - uv_se.y - uv_se.x);\n    \n    \/\/ compute angle of rotation from curl\n    float sc = cs * sign(curl) * pow(abs(curl), pwr);\n    \n    \/\/ calculate divergence\n    \/\/ vectors point inwards towards the center point\n    float div  = uv_s.y - uv_n.y - uv_e.x + uv_w.x + sq2 * (uv_nw.x - uv_nw.y - uv_ne.x - uv_ne.y + uv_sw.x + uv_sw.y + uv_se.y - uv_se.x);\n    \n    vec2 norm = normz(uv.xy);\n    \n    float sdx = uv.z + dp * uv.x * div + pl * lapl.z;\n    float sdy = uv.w + dp * uv.y * div + pl * lapl.w;\n\n    vec2 ab = advect(vec2(uv.x, uv.y), vUv, texel, ad).xy;\n    \n    \/\/ temp values for the update rule\n    float ta = amp * ab.x + ls * lapl.x + norm.x * ps * lapl.z + ds * sdx;\n    float tb = amp * ab.y + ls * lapl.y + norm.y * ps * lapl.w + ds * sdy;\n\n    \/\/ rotate\n    float a = ta * cos(sc) - tb * sin(sc);\n    float b = ta * sin(sc) + tb * cos(sc);\n    \n    vec4 abd = upd * uv + (1.0 - upd) * vec4(a,b,sdx,sdy);\n    \n    fragColor = vec4(abd);\n    \n    abd.xy = clamp(length(abd.xy) > 1.0 ? normz(abd.xy) : abd.xy, -1.0, 1.0);\n    fragColor = vec4(abd);\n    \n}","name":"Buffer B","description":"","type":"buffer"},{"inputs":[{"id":257,"src":"\/media\/previz\/buffer00.png","ctype":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":257,"src":"\/media\/previz\/buffer00.png","ctype":"buffer","channel":2,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":257,"src":"\/media\/previz\/buffer00.png","ctype":"buffer","channel":3,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":260,"src":"\/media\/previz\/buffer03.png","ctype":"buffer","channel":1,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":259,"channel":0}],"code":"\/\/ created by florian berger (flockaroo) - 2016\n\/\/ License Creative Commons Attribution-NonCommercial-ShareAlike 3.0 Unported License.\n\n\/\/ single pass CFD\n\/\/ ---------------\n\/\/ this is some \"computational flockarooid dynamics\" ;)\n\/\/ the self-advection is done purely rotational on all scales. \n\/\/ therefore i dont need any divergence-free velocity field. \n\/\/ with stochastic sampling i get the proper \"mean values\" of rotations \n\/\/ over time for higher order scales.\n\/\/\n\/\/ try changing \"RotNum\" for different accuracies of rotation calculation\n\/\/ for even RotNum uncomment the line #define SUPPORT_EVEN_ROTNUM\n\n#define RotNum 5\n\/\/#define SUPPORT_EVEN_ROTNUM\n\n#define Res  iChannelResolution[0]\n#define Res1 iChannelResolution[1]\n\n#define keyTex iChannel3\n#define KEY_I texture(keyTex,vec2((105.5-32.0)\/256.0,(0.5+0.0)\/3.0)).x\n\nconst float ang = 2.0*3.1415926535\/float(RotNum);\nmat2 m = mat2(cos(ang),sin(ang),-sin(ang),cos(ang));\nmat2 mh = mat2(cos(ang*0.5),sin(ang*0.5),-sin(ang*0.5),cos(ang*0.5));\n\nvec4 randS(vec2 uv)\n{\n    return texture(iChannel1,uv*Res.xy\/Res1.xy)-vec4(0.5);\n}\n\nfloat getRot(vec2 pos, vec2 b)\n{\n    vec2 p = b;\n    float rot=0.0;\n    for(int i=0;i<RotNum;i++)\n    {\n        rot+=dot(texture(iChannel0,fract((pos+p)\/Res.xy)).xy-vec2(0.5),p.yx*vec2(1,-1));\n        p = m*p;\n    }\n    return rot\/float(RotNum)\/dot(b,b);\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord )\n{\n    vec2 pos = fragCoord.xy;\n    float rnd = randS(vec2(float(iFrame)\/Res.x,0.5\/Res1.y)).x;\n    \n    vec2 b = vec2(cos(ang*rnd),sin(ang*rnd));\n    vec2 v=vec2(0);\n    float bbMax=0.7*Res.y; bbMax*=bbMax;\n    for(int l=0;l<20;l++)\n    {\n        if ( dot(b,b) > bbMax ) break;\n        vec2 p = b;\n        for(int i=0;i<RotNum;i++)\n        {\n#ifdef SUPPORT_EVEN_ROTNUM\n            v+=p.yx*getRot(pos+p,-mh*b);\n#else\n            \/\/ this is faster but works only for odd RotNum\n            v+=p.yx*getRot(pos+p,b);\n#endif\n            p = m*p;\n        }\n        b*=2.0;\n    }\n    \n    fragColor=texture(iChannel2,fract((pos+v*vec2(-1,1)*2.0)\/Res.xy));\n    \n    \/\/ add a little \"motor\" in the center\n\/\/    vec2 scr=(fragCoord.xy\/Res.xy)*2.0-vec2(1.0);\n \/\/   fragColor.xy += (0.000251*scr.xy \/ (dot(scr,scr)\/0.1+0.3));\n    \n    if(iFrame<=4 || KEY_I>0.5) fragColor=texture(iChannel2,fragCoord.xy\/Res.xy);\n}\n","name":"Buffer C","description":"","type":"buffer"},{"inputs":[{"id":5,"src":"\/media\/a\/8de3a3924cb95bd0e95a443fff0326c869f9d4979cd1d5b6e94e2a01f5be53e9.jpg","ctype":"texture","channel":1,"sampler":{"filter":"mipmap","wrap":"repeat","vflip":"true","srgb":"false","internal":"byte"},"published":1},{"id":258,"src":"\/media\/previz\/buffer01.png","ctype":"buffer","channel":0,"sampler":{"filter":"linear","wrap":"clamp","vflip":"true","srgb":"false","internal":"byte"},"published":1}],"outputs":[{"id":260,"channel":0}],"code":"\n\/\/ displacement amount\n#define DISP_SCALE 3.0\n\n\/\/ chromatic dispersion samples\n#define SAMPLES 256\n\n\/\/ contrast\n#define SIGMOID_CONTRAST 12.0\n\n\/\/ channels to use for displacement, either xy or zw\n#define CH zw\n\n\nvec3 contrast(vec3 x) {\n\treturn 1.0 \/ (1.0 + exp(-SIGMOID_CONTRAST * (x - 0.5)));    \n}\n\nvec2 normz(vec2 x) {\n\treturn x == vec2(0) ? vec2(0) : normalize(x);\n}\n\n\/*\n\tThis function supplies a weight vector for each color channel.\n\tIt's analogous to (but not a physically accurate model of)\n\tthe response curves for each of the 3 cone types in the human eye.\n\tThe three functions for red, green, and blue have the same integral\n    over [0, 1], which is 1\/3.\n    Here are some other potential terms for the green weight that \n\tintegrate to 1\/3:\n        2.0*(1-x)*x\n        10.0*((1-x)*x)^2\n        46.667*((1-i)*i)^3\n        210.0*((1-x)*x)^4\n        924.0*((1-x)*x)^5\n    By the way, this series of coefficients is OEIS A004731 divided by 3,\n    which is a pretty interesting series: https:\/\/oeis.org\/A002457\n*\/\nvec3 sampleWeights(float i) {\n\treturn vec3(i * i, 46.6666*pow((1.0-i)*i,3.0), (1.0 - i) * (1.0 - i));\n}\n\nvec3 sampleDisp(vec2 uv, vec2 dispNorm, float disp) {\n    vec3 col = vec3(0);\n    const float SD = 1.0 \/ float(SAMPLES);\n    float wl = 0.0;\n    vec3 denom = vec3(0);\n    for(int i = 0; i < SAMPLES; i++) {\n        vec3 sw = sampleWeights(wl);\n        denom += sw;\n        col += sw * texture(iChannel1, uv + dispNorm * disp * wl).xyz;\n        wl  += SD;\n    }\n    \n    \/\/ For a large enough number of samples,\n    \/\/ the return below is equivalent to 3.0 * col * SD;\n    return col \/ denom;\n}\n\nvoid mainImage( out vec4 fragColor, in vec2 fragCoord ){\n    vec2 texel = 1. \/ iResolution.xy;\n    vec2 uv = fragCoord.xy \/ iResolution.xy;\n\n    vec2 n  = vec2(0.0, texel.y);\n    vec2 e  = vec2(texel.x, 0.0);\n    vec2 s  = vec2(0.0, -texel.y);\n    vec2 w  = vec2(-texel.x, 0.0);\n\n    vec2 d   = texture(iChannel0, uv).CH;\n    vec2 d_n = texture(iChannel0, fract(uv+n)).CH;\n    vec2 d_e = texture(iChannel0, fract(uv+e)).CH;\n    vec2 d_s = texture(iChannel0, fract(uv+s)).CH;\n    vec2 d_w = texture(iChannel0, fract(uv+w)).CH; \n\n    \/\/ antialias our vector field by blurring\n    vec2 db = 0.4 * d + 0.15 * (d_n+d_e+d_s+d_w);\n\n    float ld = length(db);\n    vec2 ln = normz(db);\n\n\tvec3 col = sampleDisp(uv, ln, DISP_SCALE * ld);\n    \n    fragColor = vec4(contrast(col), 1.0);\n\n}","name":"Buffer D","description":"","type":"buffer"}]}}